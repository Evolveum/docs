= MidPoint In Container
:page-nav-title: Containers
:page-display-order: 20
:page-liquid:
:toc: float-right
:toclevels: 4
:page-keywords:  [ 'install', 'container' ]

{% for v in site.data.midpoint-versions %}{% if v.status == null or v.status == "released" %}{% assign lastReleased = v %}{% endif %}{% endfor %}

== Quick Start

The containers are the easiest and the fastest way how to start working with midPoint.
In case this is your the fist contact with midPoint please see the xref:../../quickstart[Quick Start] page which contain basic information useful in case of the first contact.

//TODO sync with quick start page...

== Benefits of midPoint in container

* dependency under full control +
The container is created with the required Java version.

* cloud friendly +
The container can be run both locally (e.g. docker, podman) or even in the cloud (e.g. kubernetes, aws, Azure, Google cloud).

* the starting state is guaranteed +
Anytime you can easily start new environment in many scenarios in fully controlled way.

* pre-configured environment +
Basic configuration is available.
The environment is almost ready to run - only small specific setting is needed.
There is available all requirements to initialize the repository. +
The image can be easily <<customization,customized>> by the configuration to cover the most of the expected usage.

[WARNING]
====
Image is based on standards from OCI (Open Container Initiative).
The documentation is focused on Docker or vanilla Kubernetes usage. +
You can use any other compatible environment.
In that case te following content is still valid for you.
Small customization of the configuration for the specific environment may be needed.
====

== Running environment

For the regular operation the repository (relation DB) is needed.
There is required native repository schema which is available for postgreSQL.
As far as we are in container environment, this is covered by additional container with PostgreSQL instance.

The structure (schema) have to be initiated in advance.
Once the correct schema version is ready, the midPoint is checking the initial object (content) and push it if necessary.

[NOTE]
====
There is available generic repository implementation which cover also other than PostgreSQL DB.
This repository schema is deprecated.
The available feature set is limited and no new features are available with these repository schema.
In case you are historically using this repository schema we strongly recommend to migrate to native repository.

The availability of deprecated generic repository schema may require the active subscription.

====

.Schema of the containerized environment (base setup)
image::containerized_env.png[]

In basic setup there are 3 containers needed.

* *repository* - *midpoint_data* in the diagram +
Currently there is no explicit requirements next to _running_ instance where is possible to connect.
+
Image : postgres +
Tag : see xref:/midpoint/release/{{ lastReleased.version }}/#database[release] notes for recommended version (e.g. 16-alpine)

* initialization of the environment - *data_init* in the diagram +
There have to be initialized the structure of the repository (*repository schema*) if needed.
Next to it there have to be proper config.xml configuration for midPoint.
All the required information is ready in the midPoint's container image.
For more information see <<envinit,dedicated chapter>>.
+
The requirement is to use the same version of the image as for container with midPoint.

* midPoint instance - *midpoint_server* in the diagram +
Once the environment is ready the midPoint itself can be started.
+
Image : evolveum/midpoint +
Tag : <released version> (e.g. {{ lastReleased.version }}-alpine )

Based on used environment there could be different approach how to cover the functionality.
For the specific information see the dedicated subpage:

* xref:./docker[docker / docker compose] related page
* xref:./kubernetes[kubernetes] page

[#envinit]
== Environment init

For successful start of the midPoint the basic configuration have to be done.
First part is related to the basic information about the environment like where is the keystore or how to connect to the repository.
Second part is related to repository structure (schema) which have to be prepared in advance.

=== configuration

The most of the information can be used in default values.
Alternatively there is possibility of using <<mpset,*MP_SET_*>> environment variables to customize (overwrite) the values without changing the files on filesystem.
The exception is values which is multi value type - in that case we are not overwriting but adding another value.

For the most of the cases the sample config.xml file is suitable with MP_SET_ variables to customize for the specific environment setting.
This file is available in the image (under doc directory structure) and can be used if it is copied to "proper" location.

To handle it there is available function in *midpoint.sh* starting script which can copy out the sample config.xml to midpoint home directory.

.initiate config.xml - use the sample available in the image
[source,bash]
----
MP_INIT_CFG=/opt/midpoint/var
/opt/midpoint/bin/midpoint.sh init-native
----

To see other option to customize the environment see the <<customization,dedicated chapter>>.

=== Repository

Repository is located in the separated container.
All the interaction is from "client" side.
For the common situation no specific interaction on repository container is needed.

With the repository usage we can face to cases:

* init new repository schema +
This is valid once the new environment is start - one time operation.
Can be conditionally executed with the environment start (e.g. demo environment) or run as separate one time operation (e.g. permanent test).

* upgrade the repository schema +
This may be required with midPoint upgrade as one time operation.
Not all version change have to require the schema upgrade.
See the xref:/midpoint/release/[release] notes for more information if is needed.

[WARNING]
====
For the proper run of ninja there have to be used the same connection setting as for "regular" run of the midPoint.
It mean the same *config.xml* and also *MP_SET_* env variable if it is used.
====

==== Init new repository

The repository structure (schema definition) is available in form of SQL script in midPoint image.
To apply we can use ninja tool which is available in the image for repository maintenance purpose.

.initiate the repository using ninja
[source,bash]
----
# it have to be run from midpoint installation path
cd /opt/midpoint

# There is separated initialization for repository and audit
#    ... as it can be separated
bin/ninja.sh -B run-sql --create --mode REPOSITORY
bin/ninja.sh -B run-sql --create --mode AUDIT
----

There is also option to have the definition conditionally executed with the every start.
In that case we can use ninja to check if the initialization is needed.

For this purpose we can ask ninja for the information about the repository.
The operational information we need is sent to error output as the standard output is used for the operation output itself.
For the simplicity we can check for the presence of "keyword" ERROR.

[NOTE]
====
In the theory we can differ between root cause of the error to filter really just the specific situation.
Technically if there is no issue with schema itself (e.g. connection issue) the initialization would not proceed anyway with the error.

We can define the requirement to successful execution for the start of other containers so simplification would not cause any issue.
====

.example of the conditional execution for the repository init
[source,bash]
----
# it have to be run from midpoint installation path
cd /opt/midpoint ;

# test for the repository status
bin/ninja.sh -B info >/dev/null 2>/tmp/ninja.log

#check for the presence of the "keyword" ERROR
grep -q "ERROR" /tmp/ninja.log && (
bin/ninja.sh -B run-sql --create --mode REPOSITORY
bin/ninja.sh -B run-sql --create --mode AUDIT
)
----

==== Upgrade the repository schema

The repository schema upgrade may be required in case of midPoint upgrade.
In case you need to proceed with this operation the ninja is here to help.

.upgrade repository schema
[source,bash]
----
# it have to be run from midpoint installation path
cd /opt/midpoint

bin/ninja.sh -B run-sql --upgrade --mode REPOSITORY
bin/ninja.sh -B run-sql --upgrade --mode AUDIT
----

[WARNING]
====
In case you are doing upgrade the repository schema upgrade not necessary have to be all required steps for midPoint upgrade.
On the other side repository schema upgrade not necessary have to be required with all the version upgrade.

Please check xref:/modpoint/release[release notes] for more information.
====

[#customization]
== Customization of the containers

The image is prepared to be flexible in usage.
All the common settings should be possible to realize without rebuilding the image.

To change the setting the available options are covered by the file located in /opt/midpoint/bin/*midpoint.sh*.

There are two ways how the file can be used .

* <<mpset,*MP_SET_*>> environment variable +
This part cover the most flexible part of the possible customization of the image.

* `<<initnative,Environment initiation>>` +
This part covert all the common needs related to the init of the environment (first run).

[NOTE]
====
Bash script defining also TRAPs. +
Without this definition the TERM or KILL signal would not be passed to the midPoint application in case of shutting down of the container.
This situation would not provide application time to properly ends operation. +
With the defined TRAPs signal properly reach the midPoint application and the operations are properly finished. +
From user point of view the termination of the container doesn't need to wait 10s timeout before environment forcing to kill the container and in read the termination take just few seconds.
====

[#initnative]
=== Environment initiation

This section is focused on handling available files.
What exactly will happen is controlled by the environment variables.
There are available several environment variables.
Following logic is applied only in case the relevant environment variable is set.

Once the required variable is set there is need to run `midpoint.sh init-native`.
This process will od all required operations.

* *MP_CHECK* +
Touch file (can be empty) which existence is checked during midpoint start.
Once the file exists it prevent start of application.
It the file is missing (or it is removed) the start continue as usual.
+
.example of the value
[source]
MP_CHECK=/opt/midpoint/var/init_in_progress
+
The usage is mainly in advanced scenarios when there is need to force midPoint to wait until the external condition is met.
In the most common use cases this option will not be useful.

[#initcfg]
* *MP_INIT_CFG* +
The default config.xml file is prepared for the generic repository.
Sample config.xml file for the native repository contain all we need to have set.
All the rest of the configuration can be set / overwrite by the *MP_SET_* prefixed environment variables.
Using this variable the native repository sample config.xml file will be copied (and properly renamed) to the directory set by the value of the variable.
+
.example of the value - target directory is /opt/midpoint/var (file will be /opt/midpoint/var/config.xml)
[source]
MP_INIT_CFG=/opt/midpoint/var
+
This option is needed all the time until there is available persistent storage (volume) for the home directory.

* *MP_DB_PW* +
The password for the database access has to be the same on the client and server side.
As far as the roles are split, the password has to be set in advance to be the same on both side of communication.
The value is the path to the file, where the generated password should be saved.
+
.example of the value - the generated password will be saved to /opt/db-pw/dbpassword
[source]
MP_DB_PW=/opt/db-pw/dbpassword
+
In case of generating of the password the step has to be done before the DB container is started.
As the preferred repository initiation is push (object is created remotely in the already running database) this cannot be done in one step.
Generating of the password for the database mean two phase init container - one for DB PW generation and second one for the repo init.

* *MP_PW* +
In case you prefer to have your own generated password for keystore, this option will interest you.
As a value the location for the file is provided.
+
.example of the value - the generated password will be saved to /opt/midpoint/var/keystorepw
[source]
MP_PW=/opt/midpoint/var/keystorepw
+
Once the password is used there have to be set the file as keystore password for the midPoint container otherwise the default "changeit" will be used.

=== Environment variables

* *MP_MP_ENTRY_POINT* +
The <<entry point, entry point>> can be used to copy some file before the system start. It is usable mainly with container approach like Docker.

* *MP_MEM_MAX* +
Alias for *JAVA_OPTS* variable *-Xmx[0-9]*. It may be usefull especially in case the "simply" key=value syntax would be prefered to the complex set of values in one variable.

* *MP_MEM_INIT* +
Alias for *JAVA_OPTS* variable *-Xms[0-9]*. It may be usefull especially in case the "simply" key=value syntax would be prefered to the complex set of values in one variable.

* [#mpset]*MP_SET_* +
To make the passing the variable for java easier there has been set "mapping" for the environment variables starting with *MP_SET_*. The result will be *-D* parameters in *JAVA_OPTS* which is already passed to java process. The benefit is in maintaining configuration mainly for midpoint run in the containers where passing additional argument mean list all of them and not only new one. With this mapping it is easier to maintain or even generate the configuration for the container instance.
+
By the processing *MP_SET_* "prefix" is removed and for the rest there is replaced _ with . (dot). The is exception _FILE which is handled. The prefix *-D* is added and the final result is added to the *JAVA_OPTS* variable which is used for the starting.

==== MP_SET_ samples

* config.xml - repository configuration +
One of the usage for *MP_SET_* prefixed environment variable is xref:/midpoint/reference/repository/configuration/#example-config-xml[repository configuration].
+
.subset of the config.xml (for illustration only)
[source,xml]
----
<?xml version="1.0"?>
<configuration>
    <midpoint>
        <repository>
            <jdbcUrl>jdbc:postgresql://localhost:5432/midpoint</jdbcUrl>
            <jdbcUsername>midpoint</jdbcUsername>
        </repository>
    </midpoint>
</configuration>
----
+
In case we want to set / overwrite these values the following structure of environment variables should be used :
+
.environment variable in Docker-compose syntax
[source,docker-compose]
----
service:
  <service_name>:
    environment:
     - MP_SET_midpoint_repository_jdbcUrl=jdbc:postgresql://localhost:5432/midpoint
     - MP_SET_midpoint_repository_jdbcUsername=midpoint
----
+
.environment variable in Kubernetes syntax
[source,kubernetes]
----
spec:
  containers:
    - name: <container_name>
      env:
        - name: MP_SET_midpoint_repository_jdbcUrl
          value: 'jdbc:postgresql://localhost:5432/midpoint'
        - name: MP_SET_midpoint_repository_jdbcUsername
          value: 'midpoint'
----
+
.environment variable in Docker syntax
[source,docker]
----
docker run -e MP_SET_midpoint_repository_jdbcUrl=jdbc:postgresql://localhost:5432/midpoint -e MP_SET_midpoint_repository_jdbcUsername=midpoint ...
----

* embedded Tomcat +
Other usage is to change embedded xref:/midpoint/devel/guides/environment/embedded-tomcat/[Tomcat setting].
+
.subset of server properties (application.yml)
[source]
----
server:
  port: 8080 # Server HTTP port.
----
+
As a example we can change the port from 8080 to 8081.
+
[source]
----
MP_SET_server_port=8081
----

[[entry-point]]
==== Entry Point
*MP_ENTRY_POINT* option is pointing to the folder in the container's filesystem, which is handled as a read only source mainly for post-initial-objects.
The content is copied to proper midpoint's structure (/opt/midpoint/var) before starting the midpoint instance with keeping the same sub folder structure.

During the processing of the *MP_ENTRY_POINT* it checks the existence of the file or file with extension .done (processed post-initial-object is renamed with suffix .done).
Once the file in any form ("exact" name or with the .done suffix) exists, the file is skipped so any future changes on the copied version are kept without overwriting - only new files are copied.
This way the post-initial-objects can be re-used several times with the same behaviour all the time.

.example of the behaviour : MP_ENTRY_POINT=/opt/entry-point
[source]
----
/opt/entry-point
- post-initial-objects
  + user.xml
  - role.xml

/opt/midpoint/var
+ post-initial-objects
  - user.xml.done
----

* *post-initial-objects* exists so no change
* *user.xml* in the destination there exists _user.xml.done_ so no action will happen
* *role.xml* does not exist so it will be copied to */opt/midpoint/var/post-initial-objects/role.xml*

[NOTE]
====
In the theory you can mount it directly to the midpoint's structure but the resulting behaviour will be, the most probably, a little bit different than expected.
With the first run there can be two possible situations:

* the mount point will be in "writable" mode +
In that case the file will be renamed with adding suffix *._done* and respective next run (with new container) will be ignoring the files.

* the mount point will be read-only mode +
The midpoint start will fail and it will not be possible to rename the file, which is handled as critical error.
====

If *MP_ENTRY_POINT* feature is not needed the following lines can be removed:

.kubernetes syntax
[source]
- MP_ENTRY_POINT=/opt/midpoint-dirs-docker-entrypoint

.docker syntax
[source]
- ./midpoint_server/container_files/mp-home:/opt/midpoint-dirs-docker-entrypoint/:ro

In case the lines are kept in the example, the directory *./midpoint_server/container_files/mp-home* should exists.
Otherwise docker-compose will create it.
As the container runs under root the newly created directory will have the permission set (UID, GID) for the root user.
To prevent this behavior prepare the directory structure in advance.

=== Volumes

Until you will attach the volume all the changes are kept only in the container which may be discarded.
The image is ready to attach the volume to midPoint home - /opt/midpoint/var.
By attaching the external store (volume) you will keep stored data from midPoint home out of container.
This way it is safe to remove the container and create new one attaching the volume (changing image version - e.g. new support branch build)

Volumes are handled in the container similar to mount points.
There may be more volumes mapped in cascade.

.midpoint structure
[source]
----
/opt/midpoint/var
+ connid-connectors
+ export
+ icf-connectors
| - connector-ssh-1.0.jar
+ idm-legacy
+ import
+ lib
| + jython-standalone-2.7.2.jar
| - ojdbc11.jar
+ log
| + midpoint.out
| - midpoint.log
+ post-initial-objects
+ schema
+ tmp
+ trace
- work
----

[NOTE]
====
* connector-ssh-1.0.jar +
** xref:/connectors/connectors/com.evolveum.polygon.connector.ssh.SshConnector/[SSH connector docs page] (internal link)

* jython-standalone-2.7.2.jar +
** xref:/midpoint/reference/support-4.8/expressions/expressions/script/python/[Python script docs page] (internal link)
** link:https://repo1.maven.org/maven2/org/python/jython-standalone/2.7.2/jython-standalone-2.7.2.jar[download] (external link)

* ojdbc11.jar
** Oracle JDBC
** link:https://www.oracle.com/database/technologies/appdev/jdbc-downloads.html[download] (external link)
====

.local filesystem structure
[source]
----
/tmp/workdir
+ connectors
| - connector-ssh-1.0.jar
- docker-compose.yml
----

In case you want to attach the subdirectory with the connector to container the following definition should be used :

.binding directory from external filesystem to container (docker syntax)
[source]
----
- ./connectors:/opt/midpoint/var/connid-connectors
----

There is also option to bind directly the file.
.binding specific file from external filesystem to container (docker syntax)
[source]
----
- ./connectors/connector-ssh-1.0.jar:/opt/midpoint/var/connid-connectors/connector-ssh-1.0.jar
----


[WARNING]
====
Once you will use the volume / mount point the original content will be hidden.
Based on the usage the original content can be copied but not in all the cases.
====

== Build the container

We are building the images in our link:https://jenkins.evolveum.com/view/midPoint-docker/[jenkins] infrastructure.
After basic tests (e.g. the environment can be started) the images are pushed to the public link:https://hub.docker.com/r/evolveum/midpoint[Docker hub] repository.
All the necessary resources for the docker image build are publicly available like other our resources on link:https://github.com/Evolveum/midpoint-docker[GitHub].

=== Structure of the image name

The name consist of the image name and the tag.
The name is "stable" in form *evolveum/midpoint*.
The tag differs the version and base OS used for the image.

Currently we are using the following Base OSs

.Used based OSs for the image and their tag suffixes
|===
| BaseOS| suffix for the tag

| Alpine
| -alpine

| Rocky Linux
| -rockylinux

| Ubuntu
|
|===

[NOTE]
====
Currently the Ubuntu based image is default - without suffix.
We are planning the swith to the apline as the default base OS.
====

.example of the tags
|====
| Version | Base Os | image

| 4.8 release
| Ubuntu
| evolveum/midpoint:4.8

| 4.8 release
| Rocky Linux
| evolveum/midpoint:4.8-rockylinux

| 4.8-support (snapshot)*
| Alpine
| evolveum/midpoint:4.8-support-alpine

| latest dev build
| Alpine
| evolveum/midpoint:latest-alpine

| latest dev build
| Ubuntu
| evolveum/midpoint:latest +
evolveum/midpoint
|====

[NOTE]
====
*Support* branch / support build is build of the working code.
It is used to cumulate the bug fixes between the releases.
If you are looking for some fix (e.g. the ticket is closed with code update ) the support build contain the fix with the first following build.
It is rolling tag so in the time it is changing.
Check for update of the image time to time.
====