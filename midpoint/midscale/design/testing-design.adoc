= Testing Design Meeting

*Guests:*

Igor
Rado
Katka
Pavol
Tony
Richard

* midPoint monitoring (performance, actuators, ...) - who?

* Technical testing - advanced coordination and design decisions make it part of the infra - who?



== Overview

The goal of _design meeting_ is to figure out design details about particular functionality of a software, particular solution, or even a methodology or process.
It is usualy applied to midPoint design.
But it may be also useful for non-technical and organizational aspects.

Design meeting is a creative, free-form discussion.
It may be following an agenda, but it is usually closer to a free-form brainstorming.

== Schedule

Evaluation of existing state for the first Milestone.

We would have another design meeting for the overal project testing, once design meetings are far in progress.

Design meetings are schedules as needed, the schedule is not fixed.
For midPoint, the design meeting usually happens at the beginning of a development cycle or milestone cycle.

== What To Discuss

=== Motivation and Requirements

We have to improve performance by order of magnitude

What is the *motivation* to discuss this topic at all?
Do customers need it?
What are the *use cases*?
Will it help make deployments better/faster?
How exactly?

*Use cases:*

* Our infrastructure has to support for heavy load/performance test: setup, init, execute, collect/monitor, evaluate and tear down the tests

* Open question: the evaluation of data (eg logs) what are the requirements from people who will need and evaluate it? Like how to collect data from nodes, what loggers to enable, when, ...


What will happen if we just do nothing?
Do we really need this?
It is worth the effort?

Should we do this now?
Maybe we can postpone it, there may be better opportunity in the future.

What are the *assumptions*?
What we expect that customers will do?
Maybe we are not certain about some requirements and we just assume something?

*Assumptions:*

* Focus is to make it work in our private cloud. No effort shall be spend on the abstractions and preparation on the other clouds.

* system components: mP, LDAP, PSQL, other resource prefer DBTables (PSQL) not files (scalability).

* We will focus on docker and dockerization, not hybrids for now (VM/Windows).

* Developers profiling only local: Prism (Pavol, Tony), partially Repo (Riso, maybe in combination with some DB profiler), GUI (open question for profiler)

* System level profiling (mP built in tool - Tracing by Pavol)

* We will concentrate on new implementation, do not concentrate on existing implementation in new releases

*Requirements:*

* Monitoring - we would need to sample environment metrics, ideally to provide with a context of a test being executed
** midPoint metrics - midPoint is doing itself, but how to leverage those data is open question
** Spring actuators - we will sample also these. open question - what data?
** Profiling - open question for now
** PSQL - performance monitoring and tuning. Open question

* We shall update system requirement page with all the information and recommendations we compile during this project
** Include also requirements for garbage collector configuration recommendations

* Space optimization - systems with tens of mio records are sensitive to consumed space. We have to measure and evaluate space consumption for new old/new versions.
We have to take into consideration DB, Filesystem, memory.
** DB mainly Auditing, but also storage for all main objects. There are also problems some indexes are much bigger than the actual data (audit index is 5:1 audit data).
** Filesystem ( logs, reports, ...).
*** For logs, we are polluting logs with much unnecessary information, log stacks, wrong log levels for typical operations, repeating the same errors (MID-5632, MID-5511)
** For memory mainly heap, when working with so many objects in the IDM logic, caches, connectors, assignments, report processing.

* Generic/system performance requirements
** Entitlement membership handling for large entitlements (groups) (MID-5785)
** Optimize change execution (MID-5566)
** Improve performance of typical operations (MID-5539)
*** Reduce number of unnecessary operation, number of evalutations and so on (templates, mappings, ...)
** Optimize the number of repository operations (MID-6147)
** Thresholds and limits (MID-5348)

* Repository

* Tasks
** User friendliness, user experience, data visibility (MID-6384, MID-5840)
** Resiliency, error recovery (MID-6674, MID-6417, MID-6416, MID-6412, MID-6345, MID-6011)
** Auto-scaling (cluster management/auto reconfig, (semi)automatic tasks distribution) (MID-6421, MID-6367)

* GUI

* Thread safety (aka Prism)
** Raw type thread safety MID-6542
** Resource and connector manager thread safety MID-5954
** Optimize object cloning on RepositoryCache MID-5465
** (Optional) Reporting/dashboards (space/performance) improvements.

* Schrodinger

* Query DSL

Do we have some *performance* or *scalability* targets?
Do we know how big a system do we want to support?
How many users, how many requests per second, special usage patterns (bursts), anything else?

*Performance and scalability goals:*

* Start with 1mio of records, target 10+ mio, in order of magnitude tens of milions

* The records are like carthesian product: 10 mio of users, each 10 accounts is like 100 milions of shadows

* Open question: number of other objects? Like roles, services, orgs? And also many assignments slow down problem

* Problem of many attributes for an object (100+).

Performance issues areas identified so far:
* To slow Tasks (multi-threads, multi-nodes, ...), re-indexing
* Handling of large groups
* slow large org structures (Maybe just GUI problem)



=== Ideas and Concepts

Idea is to have unit performance and system performance.


When thinking about the use cases, do not limit your thoughts to just that one specific use case.
Think about generic mechanisms, broader principles.
Focus on *concepts* and ideas, rather than algorithms.
Design mechanism that can handle your use case, and thousands of similar use cases as well.
Design *generic re-usable mechanisms*.

Make sure the new mechanisms work well with existing mechanisms.
We are looking for *synergies*.
We want to combine mechanisms together into more flexible and more powerful solutions.

=== Implementation

TODO: feasibility

=== Performance and Scalability Considerations

TODO

=== Testability Considerations

Make sure that the functionality can be tested.
Think about the testing process.
Can this be teste by the ususal mechanisms that we have?
Will we need some special environment or setup?

=== Security Considerations

TODO

=== Rolling Wave Design

TODO

== Write It Down

Notes from design meeting at the appropriate place.
For midPoint, the appropriate place is usually https://docs.evolveum.com/midpoint/devel/design/[Design Notes at docs] for public notes, or https://guide.priv.evolveum.com/midpoint/notes/[MidPoint Design Notes at guide] for private notes.

Do not forget to document:

* *Requirements* and *assumptions*. Interesting *use cases*.

* Outline of the *approach*, important aspects of algorithms, schemas and so on.

* *Decisions* that were made, also the explanation or *motivation* _why_ the decision was made.

* Outline of a *plan*.
What do we implement now?
What parts will remain to be implemented later?

* *Risks* and challenges.
What parts are likely to be problematic?
Where can the design fail?

* *Open questions*.
What we cannot answer now?
What problems remain to be solved later?
